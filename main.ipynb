{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dca9120",
   "metadata": {},
   "source": [
    "### Installing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdf038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251b6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88214b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47d667cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f41c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e87a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3e9be0a-5c16-4c0f-b92a-2fe3dca3ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing all the needed libraries for the project:\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import statsmodels.api as sm1\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model   import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import TimeSeriesSplit,ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection  import PredefinedSplit, GridSearchCV\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import gdown\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1378026-1957-41fc-afed-c4ab4898b52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1drMM8_c-43cOmGjirp4-CRz1RBwgFK_V\n",
      "To: /Users/goutham/Desktop/systematic_trading/prices.csv\n",
      "100%|██████████████████████████████████████| 34.8M/34.8M [00:01<00:00, 18.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded prices\n",
      "Loading prices_train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1RmrpUfiqfqOp5Jb5attauKcltLEx1zKh\n",
      "To: /Users/goutham/Desktop/systematic_trading/prices_train.csv\n",
      "100%|██████████████████████████████████████| 26.1M/26.1M [00:01<00:00, 22.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded prices_train\n",
      "Loading prices_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ONursxl7CKdAlf0t_Slmy2_w_Bzj2QbB\n",
      "To: /Users/goutham/Desktop/systematic_trading/prices_test.csv\n",
      "100%|██████████████████████████████████████| 8.66M/8.66M [00:00<00:00, 23.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded prices_test\n"
     ]
    }
   ],
   "source": [
    "# Define Google Drive file IDs\n",
    "prices_id        = \"1drMM8_c-43cOmGjirp4-CRz1RBwgFK_V\"\n",
    "prices_train_id  = \"1RmrpUfiqfqOp5Jb5attauKcltLEx1zKh\"\n",
    "prices_test_id   = \"1ONursxl7CKdAlf0t_Slmy2_w_Bzj2QbB\"\n",
    "\n",
    "# Download and load prices\n",
    "print(\"Loading prices...\")\n",
    "gdown.download(f\"https://drive.google.com/uc?id={prices_id}\", \"prices.csv\", quiet=False)\n",
    "prices = pd.read_csv(\"prices.csv\", parse_dates=True, index_col=0)\n",
    "print(\"✓ Loaded prices\")\n",
    "\n",
    "# Download and load training set\n",
    "print(\"Loading prices_train...\")\n",
    "gdown.download(f\"https://drive.google.com/uc?id={prices_train_id}\", \"prices_train.csv\", quiet=False)\n",
    "prices_train = pd.read_csv(\"prices_train.csv\", parse_dates=True, index_col=0)\n",
    "print(\"✓ Loaded prices_train\")\n",
    "\n",
    "# Download and load test set\n",
    "print(\"Loading prices_test...\")\n",
    "gdown.download(f\"https://drive.google.com/uc?id={prices_test_id}\", \"prices_test.csv\", quiet=False)\n",
    "prices_test = pd.read_csv(\"prices_test.csv\", parse_dates=True, index_col=0)\n",
    "print(\"✓ Loaded prices_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d1907a-9be1-4376-9451-86bcdf30be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_train_meta = prices_train.copy()# for meta labelling later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f597c021-6689-4bf2-949c-752c73b1239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_train.drop(['coin','regime','ret_regime_1','cumret_regime_1','ret_regime_2','cumret_regime_0', 'ret_regime_1', 'cumret_regime_1', 'ret_regime_2',\n",
    "       'cumret_regime_2','t1','tVal','windowSize','day'],axis=1,inplace=True)\n",
    "prices_test.drop(['coin','regime','ret_regime_1','cumret_regime_1','ret_regime_2','cumret_regime_0', 'ret_regime_1', 'cumret_regime_1', 'ret_regime_2',\n",
    "       'cumret_regime_2','t1','tVal','windowSize','day'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31637707",
   "metadata": {},
   "source": [
    "### Normalising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072bcc62-f8c3-4848-b1f1-b83376af718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Returns a ColumnTransformer that:\n",
    "      - Log-transforms and then z-scores MVRV, NVT\n",
    "      - Takes the log-difference of n_unique_addresses, then z-scores\n",
    "      - Log1p‐transforms exchange_volume, then z-scores\n",
    "      - Scales (z-scores) all the remaining continuous features\n",
    "      - Leaves binary features untouched (“passthrough”)\n",
    "\n",
    "    Usage:\n",
    "      preprocessor = preprocess_data(df)\n",
    "      X_transformed = preprocessor.fit_transform(df)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) Identify all columns of interest ---\n",
    "    # (a) special columns that need custom transforms\n",
    "    special_log_cols     = ['MVRV', 'nvt']\n",
    "    special_logdiff_cols = ['n_unique_addresses']\n",
    "    special_log1p_cols   = ['exchange_volume']\n",
    "\n",
    "    # (b) columns that were previously in “continuous_cols”\n",
    "    returns_vol_cols = [\n",
    "        c for c in df.columns\n",
    "        if c.startswith('return') or c.startswith('log_return') or c.startswith('volatility')\n",
    "    ]\n",
    "    ema_cols = [c for c in df.columns if c in ['ema21', 'ema35', 'ema80', 'ema250']]\n",
    "    sma_cols = [c for c in df.columns if c in ['sma50', 'sma200', 'sma20']]\n",
    "    other_cont = [\n",
    "        'rsi14','bb_percent_b','bb_bandwidth','macd_line','macd_hist',\n",
    "        'adx14','obv','bb_mid','bb_upper','bb_lower','bb_percent_b','bb_bandwidth',\n",
    "        'plus_di14','minus_di14','%K','%D','obv_sma20'\n",
    "    ]\n",
    "\n",
    "    # (c) combine & remove the “special” ones\n",
    "    all_continuous = sma_cols + returns_vol_cols + ema_cols + other_cont + ['volume', 'vwap']\n",
    "    # Now remove special-handled columns (they’ll be processed in their own pipelines)\n",
    "    rest_continuous = [\n",
    "        c for c in all_continuous\n",
    "        if c not in special_log_cols + special_logdiff_cols + special_log1p_cols\n",
    "    ]\n",
    "\n",
    "    # (d) binary columns get “passthrough” (unscaled)\n",
    "    binary_cols = [\n",
    "        c for c in df.columns\n",
    "        if c.endswith('cross')\n",
    "        or c.endswith('above')\n",
    "        or c.endswith('below')\n",
    "        or c.startswith('is')\n",
    "    ]\n",
    "\n",
    "    # --- 2) Build small helper functions for the custom transforms ---\n",
    "\n",
    "    # 2a) Log‐transform (with a tiny offset if you worry about zeros):\n",
    "    log_transform = FunctionTransformer(np.log1p, validate=True)\n",
    "    # You could also use np.log if you know there are no zeros or negatives:\n",
    "    # log_transform = FunctionTransformer(lambda x: np.log(x), validate=True)\n",
    "\n",
    "    # 2b) Log‐difference (i.e. first‐difference of the log)\n",
    "    def logdiff_column(X):\n",
    "        \"\"\"\n",
    "        X will be a 2D array of shape (n_samples, 1).\n",
    "        We take np.log on that column, then do a forward difference,\n",
    "        and fill the first row's diff with 0. Finally reshape back to (n_samples, 1).\n",
    "        \"\"\"\n",
    "        col = X.astype(float).ravel()           # shape (n_samples,)\n",
    "        logged = np.log1p(col)                  # or np.log(col) if no zeros\n",
    "        diffed = np.diff(logged, prepend=logged[0])  # shape (n_samples,)\n",
    "        return diffed.reshape(-1, 1)             # back to 2D\n",
    "\n",
    "    logdiff_transform = FunctionTransformer(logdiff_column, validate=True)\n",
    "\n",
    "    # 2c) Log1p‐transform (log(1+x)) for exchange_volume\n",
    "    log1p_transform = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "    # --- 3) Build pipelines for each group ---\n",
    "\n",
    "    # 3a) MVRV & NVT:  log → z-score\n",
    "    mvrv_pipeline = Pipeline([\n",
    "        ('log',    log_transform),        # apply np.log1p\n",
    "        ('scale',  StandardScaler()),     # then z-score\n",
    "    ])\n",
    "\n",
    "    nvt_pipeline = Pipeline([\n",
    "        ('log',    log_transform),\n",
    "        ('scale',  StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    # 3b) n_unique_addresses: log‐difference → z-score\n",
    "    nua_pipeline = Pipeline([\n",
    "        ('logdiff', logdiff_transform),\n",
    "        ('scale',   StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    # 3c) exchange_volume: log1p → z-score\n",
    "    exch_pipeline = Pipeline([\n",
    "        ('log1p',  log1p_transform),\n",
    "        ('scale',  StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    # 3d) “Everything else” continuous: just z-score\n",
    "    rest_pipeline = Pipeline([\n",
    "        ('scale', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # --- 4) Assemble ColumnTransformer ---\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        # log→z for MVRV\n",
    "        ('mvrv_log',     mvrv_pipeline,     ['MVRV']),\n",
    "        # log→z for NVT\n",
    "        ('nvt_log',      nvt_pipeline,      ['nvt']),\n",
    "        # logdiff→z for n_unique_addresses\n",
    "        ('nua_logdiff',  nua_pipeline,      ['n_unique_addresses']),\n",
    "        # log1p→z for exchange_volume\n",
    "        ('exch_log1p',   exch_pipeline,     ['exchange_volume']),\n",
    "        # all the other continuous features get plain z-score\n",
    "        ('rest_cont_z',  rest_pipeline,     rest_continuous),\n",
    "        # binary features pass through unchanged\n",
    "        ('passthrough_bin', 'passthrough',  binary_cols),\n",
    "    ], remainder='drop')  # Drop any columns not explicitly listed above.\n",
    "\n",
    "    return preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32217fab-fe03-4695-9c7c-0937b881e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = preprocess_data(prices_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04657426-b1cc-4b32-b4f6-78613768182f",
   "metadata": {},
   "source": [
    "### Building a baseline primary model (Randomforest, no hyperparams tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b830f63-616b-4a7b-b617-6a1533ef8c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', RandomForestClassifier(n_estimators=200,\n",
    "                                   min_samples_leaf=5,\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7688c7a7-3f14-49c2-8ffb-04cc3de836d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prices_train = prices_train.drop(['bin'],axis=1)\n",
    "y_prices_train = prices_train['bin']\n",
    "X_prices_test = prices_test.drop(['bin'],axis=1)\n",
    "y_prices_test = prices_test['bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc96e671-b607-426e-9fcc-5f01a34266b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;mvrv_log&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;log&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                                       validate=True)),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;MVRV&#x27;]),\n",
       "                                                 (&#x27;nvt_log&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;log&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                                       validate=True)),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;nvt&#x27;]),\n",
       "                                                 (&#x27;nua_logdiff&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;log...\n",
       "                                                   &#x27;sto_death_cross&#x27;,\n",
       "                                                   &#x27;price_vwap_golden_cross&#x27;,\n",
       "                                                   &#x27;price_vwap_death_cross&#x27;,\n",
       "                                                   &#x27;bb_cross_above&#x27;,\n",
       "                                                   &#x27;bb_cross_below&#x27;,\n",
       "                                                   &#x27;rsi70_cross_above&#x27;,\n",
       "                                                   &#x27;rsi70_cross_below&#x27;,\n",
       "                                                   &#x27;rsi30_cross_above&#x27;,\n",
       "                                                   &#x27;rsi30_cross_below&#x27;,\n",
       "                                                   &#x27;obv_golden_cross&#x27;,\n",
       "                                                   &#x27;obv_death_cross&#x27;,\n",
       "                                                   &#x27;is_regime_0&#x27;, &#x27;is_regime_1&#x27;,\n",
       "                                                   &#x27;is_regime_2&#x27;])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 RandomForestClassifier(min_samples_leaf=5, n_estimators=200,\n",
       "                                        n_jobs=-1, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;mvrv_log&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;log&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                                       validate=True)),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;MVRV&#x27;]),\n",
       "                                                 (&#x27;nvt_log&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;log&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                                       validate=True)),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;nvt&#x27;]),\n",
       "                                                 (&#x27;nua_logdiff&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;log...\n",
       "                                                   &#x27;sto_death_cross&#x27;,\n",
       "                                                   &#x27;price_vwap_golden_cross&#x27;,\n",
       "                                                   &#x27;price_vwap_death_cross&#x27;,\n",
       "                                                   &#x27;bb_cross_above&#x27;,\n",
       "                                                   &#x27;bb_cross_below&#x27;,\n",
       "                                                   &#x27;rsi70_cross_above&#x27;,\n",
       "                                                   &#x27;rsi70_cross_below&#x27;,\n",
       "                                                   &#x27;rsi30_cross_above&#x27;,\n",
       "                                                   &#x27;rsi30_cross_below&#x27;,\n",
       "                                                   &#x27;obv_golden_cross&#x27;,\n",
       "                                                   &#x27;obv_death_cross&#x27;,\n",
       "                                                   &#x27;is_regime_0&#x27;, &#x27;is_regime_1&#x27;,\n",
       "                                                   &#x27;is_regime_2&#x27;])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 RandomForestClassifier(min_samples_leaf=5, n_estimators=200,\n",
       "                                        n_jobs=-1, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">prep: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;mvrv_log&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;log&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                      validate=True)),\n",
       "                                                 (&#x27;scale&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;MVRV&#x27;]),\n",
       "                                (&#x27;nvt_log&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;log&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                      validate=True)),\n",
       "                                                 (&#x27;scale&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;nvt&#x27;]),\n",
       "                                (&#x27;nua_logdiff&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;logdiff&#x27;,\n",
       "                                                  FunctionTransforme...\n",
       "                                  &#x27;di14_golden_cross&#x27;, &#x27;di14_death_cross&#x27;,\n",
       "                                  &#x27;price_sma20_golden_cross&#x27;,\n",
       "                                  &#x27;price_sma20_death_cross&#x27;, &#x27;sto_golden_cross&#x27;,\n",
       "                                  &#x27;sto_death_cross&#x27;, &#x27;price_vwap_golden_cross&#x27;,\n",
       "                                  &#x27;price_vwap_death_cross&#x27;, &#x27;bb_cross_above&#x27;,\n",
       "                                  &#x27;bb_cross_below&#x27;, &#x27;rsi70_cross_above&#x27;,\n",
       "                                  &#x27;rsi70_cross_below&#x27;, &#x27;rsi30_cross_above&#x27;,\n",
       "                                  &#x27;rsi30_cross_below&#x27;, &#x27;obv_golden_cross&#x27;,\n",
       "                                  &#x27;obv_death_cross&#x27;, &#x27;is_regime_0&#x27;,\n",
       "                                  &#x27;is_regime_1&#x27;, &#x27;is_regime_2&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">mvrv_log</label><div class=\"sk-toggleable__content\"><pre>[&#x27;MVRV&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;, validate=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">nvt_log</label><div class=\"sk-toggleable__content\"><pre>[&#x27;nvt&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;, validate=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">nua_logdiff</label><div class=\"sk-toggleable__content\"><pre>[&#x27;n_unique_addresses&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function preprocess_data.&lt;locals&gt;.logdiff_column at 0x30fa9ef80&gt;,\n",
       "                    validate=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">exch_log1p</label><div class=\"sk-toggleable__content\"><pre>[&#x27;exchange_volume&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;, validate=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">rest_cont_z</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sma50&#x27;, &#x27;sma200&#x27;, &#x27;sma20&#x27;, &#x27;log_return&#x27;, &#x27;return24&#x27;, &#x27;return30&#x27;, &#x27;return120&#x27;, &#x27;log_return30&#x27;, &#x27;log_return120&#x27;, &#x27;volatility15&#x27;, &#x27;volatility200&#x27;, &#x27;ema21&#x27;, &#x27;ema35&#x27;, &#x27;ema80&#x27;, &#x27;ema250&#x27;, &#x27;rsi14&#x27;, &#x27;bb_percent_b&#x27;, &#x27;bb_bandwidth&#x27;, &#x27;macd_line&#x27;, &#x27;macd_hist&#x27;, &#x27;adx14&#x27;, &#x27;obv&#x27;, &#x27;bb_mid&#x27;, &#x27;bb_upper&#x27;, &#x27;bb_lower&#x27;, &#x27;bb_percent_b&#x27;, &#x27;bb_bandwidth&#x27;, &#x27;plus_di14&#x27;, &#x27;minus_di14&#x27;, &#x27;%K&#x27;, &#x27;%D&#x27;, &#x27;obv_sma20&#x27;, &#x27;volume&#x27;, &#x27;vwap&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough_bin</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ema21_ema80_golden_cross&#x27;, &#x27;ema21_ema80_death_cross&#x27;, &#x27;sma50_sma200_golden_cross&#x27;, &#x27;sma50_sma200_death_cross&#x27;, &#x27;macd_golden_cross&#x27;, &#x27;macd_death_cross&#x27;, &#x27;di14_golden_cross&#x27;, &#x27;di14_death_cross&#x27;, &#x27;price_sma20_golden_cross&#x27;, &#x27;price_sma20_death_cross&#x27;, &#x27;sto_golden_cross&#x27;, &#x27;sto_death_cross&#x27;, &#x27;price_vwap_golden_cross&#x27;, &#x27;price_vwap_death_cross&#x27;, &#x27;bb_cross_above&#x27;, &#x27;bb_cross_below&#x27;, &#x27;rsi70_cross_above&#x27;, &#x27;rsi70_cross_below&#x27;, &#x27;rsi30_cross_above&#x27;, &#x27;rsi30_cross_below&#x27;, &#x27;obv_golden_cross&#x27;, &#x27;obv_death_cross&#x27;, &#x27;is_regime_0&#x27;, &#x27;is_regime_1&#x27;, &#x27;is_regime_2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_leaf=5, n_estimators=200, n_jobs=-1,\n",
       "                       random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('mvrv_log',\n",
       "                                                  Pipeline(steps=[('log',\n",
       "                                                                   FunctionTransformer(func=<ufunc 'log1p'>,\n",
       "                                                                                       validate=True)),\n",
       "                                                                  ('scale',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['MVRV']),\n",
       "                                                 ('nvt_log',\n",
       "                                                  Pipeline(steps=[('log',\n",
       "                                                                   FunctionTransformer(func=<ufunc 'log1p'>,\n",
       "                                                                                       validate=True)),\n",
       "                                                                  ('scale',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['nvt']),\n",
       "                                                 ('nua_logdiff',\n",
       "                                                  Pipeline(steps=[('log...\n",
       "                                                   'sto_death_cross',\n",
       "                                                   'price_vwap_golden_cross',\n",
       "                                                   'price_vwap_death_cross',\n",
       "                                                   'bb_cross_above',\n",
       "                                                   'bb_cross_below',\n",
       "                                                   'rsi70_cross_above',\n",
       "                                                   'rsi70_cross_below',\n",
       "                                                   'rsi30_cross_above',\n",
       "                                                   'rsi30_cross_below',\n",
       "                                                   'obv_golden_cross',\n",
       "                                                   'obv_death_cross',\n",
       "                                                   'is_regime_0', 'is_regime_1',\n",
       "                                                   'is_regime_2'])])),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(min_samples_leaf=5, n_estimators=200,\n",
       "                                        n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_prices_train,y_prices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1d16882-dee4-4a70-ba19-527bf15cf81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Base RF Model:\n",
      "0.5362954414310445\n",
      "Classification matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.0000    0.0000    0.0000         0\n",
      "         1.0     1.0000    0.5363    0.6982      8665\n",
      "\n",
      "    accuracy                         0.5363      8665\n",
      "   macro avg     0.5000    0.2681    0.3491      8665\n",
      "weighted avg     1.0000    0.5363    0.6982      8665\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0]\n",
      " [4018 4647]]\n"
     ]
    }
   ],
   "source": [
    "rf_base_pred = pipe.predict(X_prices_test)\n",
    "print('Accuracy Score for Base RF Model:')\n",
    "print(accuracy_score(rf_base_pred,y_prices_test))\n",
    "print(\"Classification matrix:\")\n",
    "print(classification_report(rf_base_pred,y_prices_test, digits=4))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(rf_base_pred,y_prices_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e07dba-5982-4c89-9cb0-7dab2548799e",
   "metadata": {},
   "source": [
    "## We run modified CV on RF, XGB and LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "800bb139-1fe6-4f9f-9276-1fc7a9cecc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = X_prices_train.index.year\n",
    "validation_years = [2018, 2019, 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dbf1b6-eba8-42dc-b6ec-3caa7f337172",
   "metadata": {},
   "source": [
    "#### RF CV parameters and function for modified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47b0f8c6-6856-4c17-a347-8557c42dd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth':    [None, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features':     ['sqrt', 0.3, 0.5]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "456421cb-e8ed-4863-92bb-d947cd765683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_hyperparams_rf(params, X, y, years, validation_years):\n",
    "    \n",
    "    # We'll store each year’s OOF predictions here, keyed by year\n",
    "    oof_preds_by_year = {}\n",
    "    \n",
    "    for val_year in validation_years:\n",
    "        # Define train index: all rows whose `year != val_year`\n",
    "        train_mask = (years != val_year)\n",
    "        val_mask   = (years == val_year)\n",
    "        \n",
    "        X_tr = X.loc[train_mask]\n",
    "        y_tr = y.loc[train_mask]\n",
    "        X_val = X.loc[val_mask]\n",
    "        # Note: y_val is not used for training, only for scoring later\n",
    "        \n",
    "        # 1) Fit RF on the two “other” years\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators       = params['n_estimators'],\n",
    "            max_depth          = params['max_depth'],\n",
    "            min_samples_leaf   = params['min_samples_leaf'],\n",
    "            max_features       = params['max_features'],\n",
    "            random_state       = 42,\n",
    "            n_jobs             = -1\n",
    "        )\n",
    "        rf.fit(X_tr, y_tr)\n",
    "        \n",
    "        # 2) Predict on val_year\n",
    "        preds_val = rf.predict(X_val)  # shape = (#rows in that year,)\n",
    "        \n",
    "        # 3) Store them\n",
    "        oof_preds_by_year[val_year] = pd.Series(\n",
    "            preds_val,\n",
    "            index = X_val.index\n",
    "        )\n",
    "    \n",
    "    # 4) Concatenate the three year‐by‐year predictions in chronological order\n",
    "    #    (so the final “full_oof_pred” has the same index & ordering as X)\n",
    "    pred_list = []\n",
    "    for y_year in validation_years:\n",
    "        pred_list.append(oof_preds_by_year[y_year])\n",
    "    full_oof_pred = pd.concat(pred_list).sort_index()\n",
    "    \n",
    "    # 5) Compute accuracy on those concatenated predictions\n",
    "    true_labels = y.loc[full_oof_pred.index]  # same index\n",
    "    score = accuracy_score(true_labels, full_oof_pred)\n",
    "    return score, full_oof_pred.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9336429-4c6a-4cd5-ab36-32fe7ef60fad",
   "metadata": {},
   "source": [
    "#### Running CV on RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd7f40e7-7ccf-4a4e-b4a3-80ab624171c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4726\n",
      "Params {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4703\n",
      "Params {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4772\n",
      "Params {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4857\n",
      "Params {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4730\n",
      "Params {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4699\n",
      "Params {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4726\n",
      "Params {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4740\n",
      "Params {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4705\n",
      "Params {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4534\n",
      "Params {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4521\n",
      "Params {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4555\n",
      "Params {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4690\n",
      "Params {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4675\n",
      "Params {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4703\n",
      "Params {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4640\n",
      "Params {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4647\n",
      "Params {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4758\n",
      "Params {'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4512\n",
      "Params {'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4436\n",
      "Params {'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4472\n",
      "Params {'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4555\n",
      "Params {'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4575\n",
      "Params {'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4568\n",
      "Params {'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4582\n",
      "Params {'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4601\n",
      "Params {'max_depth': None, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4576\n",
      "Params {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4468\n",
      "Params {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4542\n",
      "Params {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4534\n",
      "Params {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4488\n",
      "Params {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4538\n",
      "Params {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4518\n",
      "Params {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4487\n",
      "Params {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4511\n",
      "Params {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4510\n",
      "Params {'max_depth': 5, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4526\n",
      "Params {'max_depth': 5, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4498\n",
      "Params {'max_depth': 5, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4496\n",
      "Params {'max_depth': 5, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4554\n",
      "Params {'max_depth': 5, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4523\n",
      "Params {'max_depth': 5, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4531\n",
      "Params {'max_depth': 5, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4534\n",
      "Params {'max_depth': 5, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4556\n",
      "Params {'max_depth': 5, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4566\n",
      "Params {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4514\n",
      "Params {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4511\n",
      "Params {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4496\n",
      "Params {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4522\n",
      "Params {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4530\n",
      "Params {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4490\n",
      "Params {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4541\n",
      "Params {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4507\n",
      "Params {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4481\n",
      "Params {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4624\n",
      "Params {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4661\n",
      "Params {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4668\n",
      "Params {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4825\n",
      "Params {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4749\n",
      "Params {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4661\n",
      "Params {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4718\n",
      "Params {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4641\n",
      "Params {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4661\n",
      "Params {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4556\n",
      "Params {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4597\n",
      "Params {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4623\n",
      "Params {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4623\n",
      "Params {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4609\n",
      "Params {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4617\n",
      "Params {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4591\n",
      "Params {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4594\n",
      "Params {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4598\n",
      "Params {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4567\n",
      "Params {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4617\n",
      "Params {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4572\n",
      "Params {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4549\n",
      "Params {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4564\n",
      "Params {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4532\n",
      "Params {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4576\n",
      "Params {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4598\n",
      "Params {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4524\n",
      "Params {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4732\n",
      "Params {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4700\n",
      "Params {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4659\n",
      "Params {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4782\n",
      "Params {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4742\n",
      "Params {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4693\n",
      "Params {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4704\n",
      "Params {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4733\n",
      "Params {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4688\n",
      "Params {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4557\n",
      "Params {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4525\n",
      "Params {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4524\n",
      "Params {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4661\n",
      "Params {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4680\n",
      "Params {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4680\n",
      "Params {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4626\n",
      "Params {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4665\n",
      "Params {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4750\n",
      "Params {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4487\n",
      "Params {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4458\n",
      "Params {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4461\n",
      "Params {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4469\n",
      "Params {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4515\n",
      "Params {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4548\n",
      "Params {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 100} → combined‐2018‐20 accuracy = 0.4574\n",
      "Params {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 200} → combined‐2018‐20 accuracy = 0.4558\n",
      "Params {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 300} → combined‐2018‐20 accuracy = 0.4547\n",
      "\n",
      "Best hyperparameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 100}\n",
      "Best 2018–2020 OOF accuracy: 0.4857240618940805\n"
     ]
    }
   ],
   "source": [
    "best_score = -np.inf\n",
    "best_params = None\n",
    "best_oof   = None\n",
    "\n",
    "for params in grid:\n",
    "    score, oof_preds = score_hyperparams_rf(\n",
    "        params,\n",
    "        X_prices_train,\n",
    "        y_prices_train,\n",
    "        years,\n",
    "        validation_years\n",
    "    )\n",
    "    print(f\"Params {params} → combined‐2018‐20 accuracy = {score:.4f}\")\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score  = score\n",
    "        best_params = params\n",
    "        best_oof    = oof_preds.copy()\n",
    "\n",
    "print(\"\\nBest hyperparameters:\", best_params)\n",
    "print(\"Best 2018–2020 OOF accuracy:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff0f3017-d4c9-4ba9-a200-54e88d2a6f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_leaf=5, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_leaf=5, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=5, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rf = RandomForestClassifier(\n",
    "    n_estimators     = best_params['n_estimators'],\n",
    "    max_depth        = best_params['max_depth'],\n",
    "    min_samples_leaf = best_params['min_samples_leaf'],\n",
    "    max_features     = best_params['max_features'],\n",
    "    random_state     = 42,\n",
    "    n_jobs           = -1\n",
    ")\n",
    "final_rf.fit(X_prices_train,y_prices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbc85455-7df8-49a7-9a1e-768c2731caf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Hyperparam optimised RF Model:\n",
      "0.5362954414310445\n",
      "Classification matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     0.0000    0.0000    0.0000         0\n",
      "         1.0     1.0000    0.5363    0.6982      8665\n",
      "\n",
      "    accuracy                         0.5363      8665\n",
      "   macro avg     0.5000    0.2681    0.3491      8665\n",
      "weighted avg     1.0000    0.5363    0.6982      8665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_final_pred = final_rf.predict(X_prices_test)\n",
    "acc = accuracy_score(rf_final_pred,y_prices_test)\n",
    "print('Accuracy Score for Hyperparam optimised RF Model:')\n",
    "print(acc)\n",
    "print(\"Classification matrix:\")\n",
    "print(classification_report(rf_final_pred,y_prices_test, digits=4))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(rf_final_pred,y_prices_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bfaf27-4fe6-4d6f-95d9-bc3066372c01",
   "metadata": {},
   "source": [
    "#### Code for XGB and LGBM CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a7b4acc-e2ae-48ba-ac76-4644ba041a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB and LGBM cannot handle -1 value, so we replace -1 with 0\n",
    "mapping = {-1:0,1:1}\n",
    "prices_train['bin'] = prices_train['bin'].map(mapping)\n",
    "prices_test['bin'] = prices_test['bin'].map(mapping)\n",
    "X_prices_train = prices_train.drop(['bin'],axis=1)\n",
    "y_prices_train = prices_train['bin']\n",
    "X_prices_test = prices_test.drop(['bin'],axis=1)\n",
    "y_prices_test = prices_test['bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3deb6bdf-2061-42b7-8caf-a91bf632a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'n_estimators':      [50, 100],\n",
    "    'max_depth':         [3, 6],\n",
    "    'learning_rate':     [0.05, 0.1],\n",
    "    'subsample':         [0.7, 1.0],\n",
    "    'colsample_bytree':  [0.7, 1.0]\n",
    "}\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators':    [50, 100],\n",
    "    'max_depth':       [-1, 5, 10],       # -1 means “no max depth” in LightGBM\n",
    "    'learning_rate':   [0.05, 0.1],\n",
    "    'num_leaves':      [31, 63],\n",
    "    'subsample':       [0.7, 1.0]\n",
    "}\n",
    "\n",
    "# Convert to list of dicts:\n",
    "xgb_grid  = list(ParameterGrid(xgb_param_grid))\n",
    "lgbm_grid = list(ParameterGrid(lgbm_param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0283385e-aadb-47ac-8b91-eaefd537d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_xgb(params, X, y, years, val_years):\n",
    "    \n",
    "    oof_by_year = {}\n",
    "    \n",
    "    # Pre‐filter numeric columns in case there’s a stray date or string column\n",
    "    numeric_cols = X.select_dtypes(include='number').columns\n",
    "    \n",
    "    for year in val_years:\n",
    "        train_mask = (years != year)\n",
    "        val_mask   = (years == year)\n",
    "        \n",
    "        X_tr  = X.loc[train_mask, numeric_cols]\n",
    "        y_tr  = y.loc[train_mask]\n",
    "        X_val = X.loc[val_mask,   numeric_cols]\n",
    "        \n",
    "        # Instantiate XGB with these params + mandatory multiclass/binary settings\n",
    "        xgb = XGBClassifier(\n",
    "            objective       = 'binary:logistic' if len(np.unique(y)) == 2 else 'multi:softprob',\n",
    "            num_class       = len(np.unique(y)) if len(np.unique(y)) > 2 else None,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric     = 'logloss',\n",
    "            random_state    = 42,\n",
    "            verbosity       = 0,\n",
    "            \n",
    "            # now unpack the grid search params:\n",
    "            n_estimators    = params['n_estimators'],\n",
    "            max_depth       = params['max_depth'],\n",
    "            learning_rate   = params['learning_rate'],\n",
    "            subsample       = params['subsample'],\n",
    "            colsample_bytree= params['colsample_bytree']\n",
    "        )\n",
    "        \n",
    "        xgb.fit(X_tr, y_tr)\n",
    "        preds_val = xgb.predict(X_val)\n",
    "        oof_by_year[year] = pd.Series(preds_val, index=X_val.index)\n",
    "    \n",
    "    # Concatenate in chronological order\n",
    "    all_preds = pd.concat([oof_by_year[y] for y in val_years]).sort_index()\n",
    "    true_lbl  = y.loc[all_preds.index]\n",
    "    score     = accuracy_score(true_lbl, all_preds)\n",
    "    return score, all_preds.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87acd2ce-d557-4a7c-b417-50f24ca9ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_xgb(params, X, y, years, val_years):\n",
    "    \n",
    "    oof_by_year = {}\n",
    "    \n",
    "    # Pre‐filter numeric columns in case there’s a stray date or string column\n",
    "    numeric_cols = X.select_dtypes(include='number').columns\n",
    "    \n",
    "    for year in val_years:\n",
    "        train_mask = (years != year)\n",
    "        val_mask   = (years == year)\n",
    "        \n",
    "        X_tr  = X.loc[train_mask, numeric_cols]\n",
    "        y_tr  = y.loc[train_mask]\n",
    "        X_val = X.loc[val_mask,   numeric_cols]\n",
    "        \n",
    "        # Instantiate XGB with these params + mandatory multiclass/binary settings\n",
    "        xgb = XGBClassifier(\n",
    "            objective       = 'binary:logistic' if len(np.unique(y)) == 2 else 'multi:softprob',\n",
    "            num_class       = len(np.unique(y)) if len(np.unique(y)) > 2 else None,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric     = 'logloss',\n",
    "            random_state    = 42,\n",
    "            verbosity       = 0,\n",
    "            \n",
    "            # now unpack the grid search params:\n",
    "            n_estimators    = params['n_estimators'],\n",
    "            max_depth       = params['max_depth'],\n",
    "            learning_rate   = params['learning_rate'],\n",
    "            subsample       = params['subsample'],\n",
    "            colsample_bytree= params['colsample_bytree']\n",
    "        )\n",
    "        \n",
    "        xgb.fit(X_tr, y_tr)\n",
    "        preds_val = xgb.predict(X_val)\n",
    "        oof_by_year[year] = pd.Series(preds_val, index=X_val.index)\n",
    "    \n",
    "    # Concatenate in chronological order\n",
    "    all_preds = pd.concat([oof_by_year[y] for y in val_years]).sort_index()\n",
    "    true_lbl  = y.loc[all_preds.index]\n",
    "    score     = accuracy_score(true_lbl, all_preds)\n",
    "    return score, all_preds.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed20471-7490-40b2-8556-43ea31e04a95",
   "metadata": {},
   "source": [
    "#### Running code for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58ff51ee-7634-4b60-9065-c558cf47491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tuning XGBoost ===\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.7} → OOF accuracy = 0.4484\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} → OOF accuracy = 0.4453\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7} → OOF accuracy = 0.4573\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} → OOF accuracy = 0.4562\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 50, 'subsample': 0.7} → OOF accuracy = 0.4516\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 50, 'subsample': 1.0} → OOF accuracy = 0.4538\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.7} → OOF accuracy = 0.4556\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100, 'subsample': 1.0} → OOF accuracy = 0.4447\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.7} → OOF accuracy = 0.4538\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} → OOF accuracy = 0.4372\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7} → OOF accuracy = 0.4688\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} → OOF accuracy = 0.4666\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 50, 'subsample': 0.7} → OOF accuracy = 0.4633\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 50, 'subsample': 1.0} → OOF accuracy = 0.4614\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.7} → OOF accuracy = 0.4533\n",
      "XGB params {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'subsample': 1.0} → OOF accuracy = 0.4597\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.7} → OOF accuracy = 0.4511\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} → OOF accuracy = 0.4455\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7} → OOF accuracy = 0.4555\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} → OOF accuracy = 0.4745\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 50, 'subsample': 0.7} → OOF accuracy = 0.4493\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 50, 'subsample': 1.0} → OOF accuracy = 0.4546\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.7} → OOF accuracy = 0.4503\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100, 'subsample': 1.0} → OOF accuracy = 0.4544\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.7} → OOF accuracy = 0.4605\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} → OOF accuracy = 0.4658\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7} → OOF accuracy = 0.4601\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} → OOF accuracy = 0.4746\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 50, 'subsample': 0.7} → OOF accuracy = 0.4507\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 50, 'subsample': 1.0} → OOF accuracy = 0.4447\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.7} → OOF accuracy = 0.4531\n",
      "XGB params {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'subsample': 1.0} → OOF accuracy = 0.4567\n",
      "\n",
      "Best XGB params: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Best XGB 2018–20 accuracy: 0.47458464813899554\n"
     ]
    }
   ],
   "source": [
    "best_xgb_score = -np.inf\n",
    "best_xgb_params = None\n",
    "best_xgb_oof    = None\n",
    "\n",
    "print(\"=== Tuning XGBoost ===\")\n",
    "for params in xgb_grid:\n",
    "    sc, oof = score_xgb(params,\n",
    "                         X_prices_train,\n",
    "                         y_prices_train,\n",
    "                         years,\n",
    "                         validation_years)\n",
    "    print(f\"XGB params {params} → OOF accuracy = {sc:.4f}\")\n",
    "    if sc > best_xgb_score:\n",
    "        best_xgb_score  = sc\n",
    "        best_xgb_params = params.copy()\n",
    "        best_xgb_oof    = oof.copy()\n",
    "\n",
    "print(\"\\nBest XGB params:\", best_xgb_params)\n",
    "print(\"Best XGB 2018–20 accuracy:\", best_xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9041c8a0-f457-4106-8389-e49e43bcd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_lgbm(params, X, y, years, val_years):\n",
    "    \n",
    "    oof_by_year = {}\n",
    "    numeric_cols = X.select_dtypes(include='number').columns\n",
    "    \n",
    "    for year in val_years:\n",
    "        train_mask = (years != year)\n",
    "        val_mask   = (years == year)\n",
    "        \n",
    "        X_tr  = X.loc[train_mask, numeric_cols]\n",
    "        y_tr  = y.loc[train_mask]\n",
    "        X_val = X.loc[val_mask,   numeric_cols]\n",
    "        \n",
    "        lgbm = LGBMClassifier(\n",
    "            objective     = 'binary' if len(np.unique(y)) == 2 else 'multiclass',\n",
    "            num_class     = len(np.unique(y)) if len(np.unique(y)) > 2 else None,\n",
    "            random_state  = 42,\n",
    "            verbosity     = -1,\n",
    "            \n",
    "            # unpack the hyperparams\n",
    "            n_estimators  = params['n_estimators'],\n",
    "            max_depth     = params['max_depth'],\n",
    "            learning_rate = params['learning_rate'],\n",
    "            num_leaves    = params['num_leaves'],\n",
    "            subsample     = params['subsample']\n",
    "        )\n",
    "        \n",
    "        lgbm.fit(X_tr, y_tr)\n",
    "        preds_val = lgbm.predict(X_val)\n",
    "        oof_by_year[year] = pd.Series(preds_val, index=X_val.index)\n",
    "    \n",
    "    all_preds = pd.concat([oof_by_year[y] for y in val_years]).sort_index()\n",
    "    true_lbl  = y.loc[all_preds.index]\n",
    "    score     = accuracy_score(true_lbl, all_preds)\n",
    "    return score, all_preds.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c4634-bc38-4826-995f-2220ab50a39e",
   "metadata": {},
   "source": [
    "#### Running code for LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9ce7607-b579-4015-a6e8-4038e97df340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning LightGBM ===\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4599\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4599\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4417\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4417\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4456\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4456\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4449\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4449\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4443\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4443\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4435\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4435\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4453\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4453\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4441\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4441\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4474\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4474\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4384\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4384\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4458\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4458\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4402\n",
      "LGBM params {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4402\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4559\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4559\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4487\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4487\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4536\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4536\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4548\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4548\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4490\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4490\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4490\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4490\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4525\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4525\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4525\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4525\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4561\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4561\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4457\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4457\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.7} → OOF accuracy = 0.4606\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 1.0} → OOF accuracy = 0.4606\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 0.7} → OOF accuracy = 0.4505\n",
      "LGBM params {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 1.0} → OOF accuracy = 0.4505\n",
      "\n",
      "Best LGBM params: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.7}\n",
      "Best LGBM 2018–20 accuracy: 0.4606318670874045\n"
     ]
    }
   ],
   "source": [
    "best_lgbm_score = -np.inf\n",
    "best_lgbm_params = None\n",
    "best_lgbm_oof    = None\n",
    "\n",
    "print(\"\\n=== Tuning LightGBM ===\")\n",
    "for params in lgbm_grid:\n",
    "    sc, oof = score_lgbm(params,\n",
    "                          X_prices_train,\n",
    "                          y_prices_train,\n",
    "                          years,\n",
    "                          validation_years)\n",
    "    print(f\"LGBM params {params} → OOF accuracy = {sc:.4f}\")\n",
    "    if sc > best_lgbm_score:\n",
    "        best_lgbm_score  = sc\n",
    "        best_lgbm_params = params.copy()\n",
    "        best_lgbm_oof    = oof.copy()\n",
    "\n",
    "print(\"\\nBest LGBM params:\", best_lgbm_params)\n",
    "print(\"Best LGBM 2018–20 accuracy:\", best_lgbm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bb2d6e4-9a70-4ffc-b44b-1bb083819eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=10, num_class=None, objective=&#x27;binary&#x27;,\n",
       "               random_state=42, subsample=0.7, verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=10, num_class=None, objective=&#x27;binary&#x27;,\n",
       "               random_state=42, subsample=0.7, verbosity=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(max_depth=10, num_class=None, objective='binary',\n",
       "               random_state=42, subsample=0.7, verbosity=-1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_xgb = XGBClassifier(\n",
    "    objective       = 'binary:logistic' if len(np.unique(y_prices_train)) == 2 else 'multi:softprob',\n",
    "    num_class       = len(np.unique(y_prices_train)) if len(np.unique(y_prices_train)) > 2 else None,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric     = 'logloss',\n",
    "    random_state    = 42,\n",
    "    verbosity       = 0,\n",
    "    \n",
    "    **best_xgb_params\n",
    ")\n",
    "final_xgb.fit(X_prices_train.select_dtypes(include='number'), y_prices_train)\n",
    "\n",
    "# Final LightGBM\n",
    "final_lgbm = LGBMClassifier(\n",
    "    objective     = 'binary' if len(np.unique(y_prices_train)) == 2 else 'multiclass',\n",
    "    num_class     = len(np.unique(y_prices_train)) if len(np.unique(y_prices_train)) > 2 else None,\n",
    "    random_state  = 42,\n",
    "    verbosity     = -1,\n",
    "    \n",
    "    **best_lgbm_params\n",
    ")\n",
    "final_lgbm.fit(X_prices_train.select_dtypes(include='number'), y_prices_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93bc0b9e-af0e-4354-b788-7f136796bbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=10, num_class=None, objective=&#x27;binary&#x27;,\n",
       "               random_state=42, subsample=0.7, verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=10, num_class=None, objective=&#x27;binary&#x27;,\n",
       "               random_state=42, subsample=0.7, verbosity=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(max_depth=10, num_class=None, objective='binary',\n",
       "               random_state=42, subsample=0.7, verbosity=-1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_xgb.fit(X_prices_train,y_prices_train)\n",
    "final_lgbm.fit(X_prices_train,y_prices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cfe3a40-17b7-4987-86f0-0e90c64432d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Final accuracy score:\n",
      "0.5362954414310445\n",
      "Classification matrix for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         0\n",
      "           1     1.0000    0.5363    0.6982      8665\n",
      "\n",
      "    accuracy                         0.5363      8665\n",
      "   macro avg     0.5000    0.2681    0.3491      8665\n",
      "weighted avg     1.0000    0.5363    0.6982      8665\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0]\n",
      " [4018 4647]]\n",
      "LGBM Final Accuracy score:\n",
      "0.5361800346220427\n",
      "Classification matrix for LGBM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         1\n",
      "           1     0.9998    0.5362    0.6981      8664\n",
      "\n",
      "    accuracy                         0.5362      8665\n",
      "   macro avg     0.4999    0.2681    0.3490      8665\n",
      "weighted avg     0.9997    0.5362    0.6980      8665\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    1]\n",
      " [4018 4646]]\n"
     ]
    }
   ],
   "source": [
    "xgb_final_predict = final_xgb.predict(X_prices_test)\n",
    "lgbm_final_predict = final_lgbm.predict(X_prices_test)\n",
    "acc_xgb = accuracy_score(xgb_final_predict,y_prices_test)\n",
    "acc_lgbm = accuracy_score(lgbm_final_predict,y_prices_test)\n",
    "print(\"XGB Final accuracy score:\")\n",
    "print(acc_xgb)\n",
    "print(\"Classification matrix for XGB:\")\n",
    "print(classification_report(xgb_final_predict,y_prices_test, digits=4))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(xgb_final_predict,y_prices_test))\n",
    "print(\"LGBM Final Accuracy score:\")\n",
    "print(acc_lgbm)\n",
    "print(\"Classification matrix for LGBM:\")\n",
    "print(classification_report(lgbm_final_predict,y_prices_test, digits=4))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(lgbm_final_predict,y_prices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2e2e02c-4e5a-4f54-b0dc-6adb3752cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred_prob_xgb = final_xgb.predict_proba(X_prices_train)\n",
    "#best_pred_prob_lgbm = final_lgbm.predict_proba(X_prices_train) I do not think we include probabilities predicted by primary models we do not use\n",
    "#best_pred_prob_rf = final_rf.predict_proba(X_prices_train)\n",
    "best_predictions = final_xgb.predict(X_prices_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668feb8b",
   "metadata": {},
   "source": [
    "### Tripple Barrier method (Meta labelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cbc28-b341-4849-bda5-b1b7701e7441",
   "metadata": {},
   "source": [
    "### We re-download the data for adding meta labels since we dropped certain features before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "723b6c1a-e327-4b0b-be14-ce91118e7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_train_meta.drop(['coin','regime','ret_regime_1','cumret_regime_1','ret_regime_2','cumret_regime_0', 'ret_regime_1', 'cumret_regime_1', 'ret_regime_2',\n",
    "       'cumret_regime_2','tVal','day'],axis=1,inplace=True)\n",
    "#prices_test.drop(['coin','regime','ret_regime_1','cumret_regime_1','ret_regime_2','cumret_regime_0', 'ret_regime_1', 'cumret_regime_1', 'ret_regime_2',\n",
    " #      'cumret_regime_2','tVal','day'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "246810a6-f412-4095-880d-b28e01ab446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_train_meta['best_pred_prob_xgb_0'] = best_pred_prob_xgb[:,0]\n",
    "prices_train_meta['best_pred_prob_xgb_1'] = best_pred_prob_xgb[:,1]\n",
    "prices_train_meta['best_predictions'] = best_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e718d-0ed4-4cf2-9154-60da5e2167a3",
   "metadata": {},
   "source": [
    "### Function to add meta-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d55a6fe-2249-4e87-8e2a-78fe66b6a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_barrier_labeling(df,\n",
    "                            price_col: str = 'close',\n",
    "                            dir_col: str   = 'best_predictions',\n",
    "                            horizon_col: str = 'windowSize',\n",
    "                            pt: float = 0.02,\n",
    "                            sl: float = 0.02):\n",
    "    \n",
    "    out = pd.DataFrame(index=df.index, columns=['t_out','barrier','y','m'])\n",
    "    prices = df[price_col].values.flatten()\n",
    "    directions = df[dir_col].fillna(0).values.flatten()\n",
    "    horizons  = df[horizon_col].fillna(0).astype(int).values.flatten()\n",
    "    N = len(df)\n",
    "\n",
    "    for idx, (p0, d, h) in enumerate(zip(prices, directions, horizons)):\n",
    "        if d == 0:\n",
    "            out.iloc[idx] = [pd.NaT, None, 0, 0]\n",
    "            continue\n",
    "\n",
    "        # compute barrier levels\n",
    "        profit_bar = p0 * (1 + d * pt)\n",
    "        stop_bar   = p0 * (1 - d * sl)\n",
    "\n",
    "        # endpoint index\n",
    "        end_idx = min(idx + h, N - 1)\n",
    "\n",
    "        y = 0\n",
    "        t_hit = df.index[end_idx]\n",
    "        barrier_hit = 'time'\n",
    "\n",
    "        # scan forward\n",
    "        for j in range(idx, end_idx + 1):\n",
    "            pj = prices[j]\n",
    "            if (d == 1 and pj >= profit_bar) or (d == -1 and pj <= profit_bar):\n",
    "                y = 1\n",
    "                t_hit = df.index[j]\n",
    "                barrier_hit = 'profit'\n",
    "                break\n",
    "            if (d == 1 and pj <= stop_bar) or (d == -1 and pj >= stop_bar):\n",
    "                y = -1\n",
    "                t_hit = df.index[j]\n",
    "                barrier_hit = 'stop'\n",
    "                break\n",
    "\n",
    "        m = int(y == d)\n",
    "        out.iloc[idx] = [t_hit, barrier_hit, y, m]\n",
    "\n",
    "    return out\n",
    "\n",
    "# Integrate into pipeline\n",
    "def add_meta_labels(df,\n",
    "                    price_col='close',\n",
    "                    dir_col='best_predictions',\n",
    "                    horizon_col='windowSize',\n",
    "                    pt=0.02, sl=0.02):\n",
    "    \"\"\"\n",
    "    Joins triple-barrier labels and meta-labels (m) onto df.\n",
    "    \"\"\"\n",
    "    labels = triple_barrier_labeling(df, price_col, dir_col, horizon_col, pt, sl)\n",
    "    return df.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e764db7b-9edd-4b64-93a2-0c264b4457fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_train_meta = add_meta_labels(prices_train_meta,price_col='close',\n",
    "                    dir_col='best_predictions',\n",
    "                    horizon_col='windowSize',\n",
    "                    pt=0.02, sl=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4d081c-2465-4f4c-8888-150a84f09e43",
   "metadata": {},
   "source": [
    "#### Remove everyhting to do with trend scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f089f0a6-fcc0-4133-bf8d-fe640b844f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_train_meta.drop(['t_out','barrier','y','windowSize','bin','t1'],axis=1,inplace=True)\n",
    "#prices_test.drop(['coin','regime','ret_regime_1','cumret_regime_1','ret_regime_2','cumret_regime_0', 'ret_regime_1', 'cumret_regime_1', 'ret_regime_2',\n",
    " #      'cumret_regime_2','tVal','day'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c52a861-cf1e-497e-bd78-f8d801089b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'volume', 'MVRV', 'n_unique_addresses',\n",
       "       'exchange_volume', 'nvt', 'log_close', 'log_vol', 'log_return',\n",
       "       'return24', 'return30', 'return120', 'log_return30', 'log_return120',\n",
       "       'volatility15', 'volatility200', 'rv_24h', 'ema21', 'ema35', 'ema80',\n",
       "       'ema250', 'vwap', 'vwap_ratio', 'rsi14', 'macd_line', 'macd_signal',\n",
       "       'macd_hist', 'bb_mid', 'bb_upper', 'bb_lower', 'bb_percent_b',\n",
       "       'bb_bandwidth', 'adx14', 'plus_di14', 'minus_di14', 'obv', 'obv_ratio',\n",
       "       'sma50', 'sma200', 'sma20', '%K', '%D', 'ema21_ema80_golden_cross',\n",
       "       'ema21_ema80_death_cross', 'sma50_sma200_golden_cross',\n",
       "       'sma50_sma200_death_cross', 'macd_golden_cross', 'macd_death_cross',\n",
       "       'di14_golden_cross', 'di14_death_cross', 'price_sma20_golden_cross',\n",
       "       'price_sma20_death_cross', 'sto_golden_cross', 'sto_death_cross',\n",
       "       'price_vwap_golden_cross', 'price_vwap_death_cross', 'bb_cross_above',\n",
       "       'bb_cross_below', 'rsi70_cross_above', 'rsi70_cross_below',\n",
       "       'rsi30_cross_above', 'rsi30_cross_below', 'obv_sma20',\n",
       "       'obv_golden_cross', 'obv_death_cross', 'ret_regime_0', 'is_regime_0',\n",
       "       'is_regime_1', 'is_regime_2', 'best_pred_prob_xgb_0',\n",
       "       'best_pred_prob_xgb_1', 'best_predictions', 'm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_train_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1218693-efc1-497d-9535-899e929da811",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prices_train_meta = prices_train_meta.drop(['m'],axis=1)\n",
    "y_prices_train_meta = prices_train_meta['m'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb45ba8",
   "metadata": {},
   "source": [
    "### Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "993fca9c-7875-4dbc-b4fd-dcafcaccefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba6ed1-4b1e-429f-8e4a-9affeebb8c2f",
   "metadata": {},
   "source": [
    "#### RF Meta model with hyperparam ptimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f6d80a9-3403-4900-92df-421f5ff8055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "→ RF best params: {'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "→ RF best CV accuracy: 0.7718631178707224\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators':    [50, 100, 200],\n",
    "    'max_depth':       [None, 5, 10],\n",
    "    'min_samples_leaf': [1, 5]\n",
    "}\n",
    "\n",
    "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_search = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',   # or 'f1' if your classes are imbalanced\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on the full meta‐training set (2018–2020), but internally CV will respect time order:\n",
    "rf_search.fit(X_prices_train_meta, y_prices_train_meta)\n",
    "\n",
    "print(\"→ RF best params:\", rf_search.best_params_)\n",
    "print(\"→ RF best CV accuracy:\", rf_search.best_score_)\n",
    "best_rf_meta = rf_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db61a99-ae74-4f05-ae41-f27ad3f2be66",
   "metadata": {},
   "source": [
    "#### XGB Meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0191a449-2a2a-41aa-a7d0-0dc649c7c31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "→ XGB best params: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "→ XGB best CV accuracy: 0.7641064638783271\n"
     ]
    }
   ],
   "source": [
    "xgb_param_grid = {\n",
    "    'n_estimators':   [50, 100, 200],\n",
    "    'max_depth':      [3, 6, 9],\n",
    "    'learning_rate':  [0.01, 0.1],\n",
    "    'subsample':      [0.7, 1.0],\n",
    "    'colsample_bytree': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_prices_train_meta, y_prices_train_meta)\n",
    "\n",
    "print(\"→ XGB best params:\", xgb_search.best_params_)\n",
    "print(\"→ XGB best CV accuracy:\", xgb_search.best_score_)\n",
    "best_xgb_meta = xgb_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0255b14-12c3-4a64-a502-631cb2838b70",
   "metadata": {},
   "source": [
    "#### LGBM Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0a59fb6-c1d4-4a04-a041-e5a9d3e7412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "→ LGBM best params: {'learning_rate': 0.01, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.7}\n",
      "→ LGBM best CV accuracy: 0.7605069708491762\n"
     ]
    }
   ],
   "source": [
    "lgbm_param_grid = {\n",
    "    'n_estimators':  [50, 100, 200],\n",
    "    'max_depth':     [-1, 5, 10],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'num_leaves':    [31, 63],\n",
    "    'subsample':     [0.7, 1.0]\n",
    "}\n",
    "\n",
    "lgbm_base = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "lgbm_search = GridSearchCV(\n",
    "    estimator=lgbm_base,\n",
    "    param_grid=lgbm_param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lgbm_search.fit(X_prices_train_meta, y_prices_train_meta)\n",
    "\n",
    "print(\"→ LGBM best params:\", lgbm_search.best_params_)\n",
    "print(\"→ LGBM best CV accuracy:\", lgbm_search.best_score_)\n",
    "best_lgbm_meta = lgbm_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadf2437-2de3-4c78-a577-eb34b4dd3995",
   "metadata": {},
   "source": [
    "#### Validate on these 3 models to find best accuracy on holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1d9c587-39bc-44d8-abe8-a374a4534788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RF-meta on final 20% hold‐out ===\n",
      "Accuracy: 0.7036685040866756\n",
      "Classification Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9979    0.3739    0.5440      2487\n",
      "           1     0.6403    0.9993    0.7805      2774\n",
      "\n",
      "    accuracy                         0.7037      5261\n",
      "   macro avg     0.8191    0.6866    0.6623      5261\n",
      "weighted avg     0.8093    0.7037    0.6687      5261\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 930 1557]\n",
      " [   2 2772]]\n",
      "\n",
      "=== XGB-meta on final 20% hold‐out ===\n",
      "Accuracy: 0.7032883482227713\n",
      "Classification Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.3723    0.5426      2487\n",
      "           1     0.6399    1.0000    0.7804      2774\n",
      "\n",
      "    accuracy                         0.7033      5261\n",
      "   macro avg     0.8200    0.6862    0.6615      5261\n",
      "weighted avg     0.8101    0.7033    0.6680      5261\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 926 1561]\n",
      " [   0 2774]]\n",
      "\n",
      "=== LGBM-meta on final 20% hold‐out ===\n",
      "Accuracy: 0.6892225812583159\n",
      "Classification Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6704    0.6739    0.6721      2487\n",
      "           1     0.7063    0.7030    0.7046      2774\n",
      "\n",
      "    accuracy                         0.6892      5261\n",
      "   macro avg     0.6883    0.6884    0.6884      5261\n",
      "weighted avg     0.6893    0.6892    0.6893      5261\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1676  811]\n",
      " [ 824 1950]]\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Create a chronological train/val split (e.g. first 80% train, last 20% test)\n",
    "n_total = len(X_prices_train_meta)\n",
    "split_index = int(n_total * 0.8)\n",
    "\n",
    "X_m_train = X_prices_train_meta.iloc[:split_index]\n",
    "y_m_train = y_prices_train_meta.iloc[:split_index]\n",
    "X_m_test  = X_prices_train_meta.iloc[split_index:]\n",
    "y_m_test  = y_prices_train_meta.iloc[split_index:]\n",
    "\n",
    "# 3.2 Fit each best‐estimator on the first 80% (if not already refit):\n",
    "best_rf_meta.fit(X_m_train, y_m_train)\n",
    "best_xgb_meta.fit(X_m_train, y_m_train)\n",
    "best_lgbm_meta.fit(X_m_train, y_m_train)\n",
    "\n",
    "# 3.3 Predict on the final 20% and report\n",
    "for name, model in [\n",
    "    (\"RF-meta\", best_rf_meta),\n",
    "    (\"XGB-meta\", best_xgb_meta),\n",
    "    (\"LGBM-meta\", best_lgbm_meta)\n",
    "]:\n",
    "    yhat = model.predict(X_m_test)\n",
    "    print(f\"\\n=== {name} on final 20% hold‐out ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_m_test, yhat))\n",
    "    print('Classification Matrix:')\n",
    "    print(classification_report(y_m_test, yhat, digits=4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_m_test, yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e002fe8-6d80-4ac1-864c-bc18ae2c760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Linear Regression Meta‐Model ===\n",
      "Accuracy: 0.6550085535069379\n",
      "Classification Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6673    0.5388    0.5962      2487\n",
      "           1     0.6474    0.7592    0.6989      2774\n",
      "\n",
      "    accuracy                         0.6550      5261\n",
      "   macro avg     0.6574    0.6490    0.6475      5261\n",
      "weighted avg     0.6568    0.6550    0.6503      5261\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1340 1147]\n",
      " [ 668 2106]]\n",
      "\n",
      "=== Lasso Meta‐Model (alpha=0.01) ===\n",
      "Accuracy: 0.7021478806310587\n",
      "Classification Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.3699    0.5401      2487\n",
      "           1     0.6390    1.0000    0.7798      2774\n",
      "\n",
      "    accuracy                         0.7021      5261\n",
      "   macro avg     0.8195    0.6850    0.6599      5261\n",
      "weighted avg     0.8097    0.7021    0.6665      5261\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 920 1567]\n",
      " [   0 2774]]\n",
      "\n",
      "=== Ridge Meta‐Model (alpha=1.0) ===\n",
      "Accuracy: 0.6426534879300513\n",
      "Classification Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6398    0.5585    0.5964      2487\n",
      "           1     0.6447    0.7181    0.6794      2774\n",
      "\n",
      "    accuracy                         0.6427      5261\n",
      "   macro avg     0.6422    0.6383    0.6379      5261\n",
      "weighted avg     0.6424    0.6427    0.6402      5261\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1389 1098]\n",
      " [ 782 1992]]\n"
     ]
    }
   ],
   "source": [
    "n = len(X_prices_train_meta)\n",
    "split_at = int(n * 0.8)\n",
    "\n",
    "X_train = X_prices_train_meta.iloc[:split_at]\n",
    "X_val   = X_prices_train_meta.iloc[split_at:]\n",
    "y_train = y_prices_train_meta.iloc[:split_at]\n",
    "y_val   = y_prices_train_meta.iloc[split_at:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "\n",
    "# 4) Fit LinearRegression, Lasso, and Ridge (all treat y_train as continuous {0,1})\n",
    "#    (a) Ordinary Least Squares\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "#    (b) Lasso (L1‐penalty); choose alpha via a small grid or stick to a default (e.g. 0.01)\n",
    "lasso = Lasso(alpha=0.01, random_state=42, max_iter=5000)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "#    (c) Ridge (L2‐penalty); choose alpha similarly (e.g. 1.0)\n",
    "ridge = Ridge(alpha=1.0, random_state=42, max_iter=5000)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5) Predict continuous “scores” on the validation set\n",
    "lr_scores    = lr.predict(X_val_scaled)\n",
    "lasso_scores = lasso.predict(X_val_scaled)\n",
    "ridge_scores = ridge.predict(X_val_scaled)\n",
    "\n",
    "# 6) Threshold at 0.5 to get discrete 0/1 labels\n",
    "lr_pred    = (lr_scores    >= 0.5).astype(int)\n",
    "lasso_pred = (lasso_scores >= 0.5).astype(int)\n",
    "ridge_pred = (ridge_scores >= 0.5).astype(int)\n",
    "\n",
    "# 7) Evaluate each as a classifier\n",
    "print(\"\\n=== Linear Regression Meta‐Model ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, lr_pred))\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_val, lr_pred, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, lr_pred))\n",
    "\n",
    "print(\"\\n=== Lasso Meta‐Model (alpha=0.01) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, lasso_pred))\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_val, lasso_pred, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, lasso_pred))\n",
    "\n",
    "print(\"\\n=== Ridge Meta‐Model (alpha=1.0) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, ridge_pred))\n",
    "print('Classification Matrix:')\n",
    "print(classification_report(y_val, ridge_pred, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, ridge_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c3415",
   "metadata": {},
   "source": [
    "### Backtesting on 2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
